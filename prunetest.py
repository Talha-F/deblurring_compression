import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import os
import copy
import argparse
import random
import test
import torch.nn.utils.prune as prune
from copy import deepcopy
import copy
import wandb
from torch.utils.data import Dataset, DataLoader
from data.data_RGB import get_training_data
from tensorboardX import SummaryWriter
from warmup_scheduler import GradualWarmupScheduler
from model.MSSNet import DeblurNet
from train.trainer_dp import Trainer

layer_filters = []
prune_layer_weights = []
res_layer_weights = []

#out1 = np.load('./out_test/original/orig1.npy')
#new1 = np.load('./out_test/original/new1.npz')
#for k,v in new1.items():
#    print(v.shape)

#non_zero_ind = torch.nonzero(torch.Tensor(out1[0,:,0,0])).flatten()
#out1 = out1[0,non_zero_ind,:,:]

#dir = sorted(os.listdir('./pruned_models'))[::-1]
model_path = './pruned_models/' + 'model_1669309767.pth'
model = torch.load(model_path)

for layer in model.modules():
    if str(type(layer)) == '<class \'model.MSSNet.ResBlock\'>':
        conv = list(layer.named_modules())[2]
        if prune.is_pruned(conv[1]):
            prune.remove(conv[1], 'weight')
#        non_zero_ind = torch.nonzero(conv[1].weight[:, 0, 0, 0]).flatten()
#        print(non_zero_ind)
#        layer_filters.append(len(non_zero_ind))
#        prune_layer_weights.append(conv[1].weight[non_zero_ind])
#        conv2 = list(layer.named_modules())[4]
#        res_layer_weights.append(conv2[1].weight[:,non_zero_ind])
torch.save({'model_state_dict':model.state_dict()}, 'prune_state.pth')

deblur_model1 = DeblurNet(wf=54, scale=42, vscale=42).cuda(0)
deblur_model2 = DeblurNet(wf=54, scale=42, vscale=42).cuda(1)
#indx = 0
#for layer in deblur_model.modules():
#    if str(type(layer)) == '<class \'model.MSSNet_pruned.ResBlock\'>':
#        conv = list(layer.named_modules())[2]
#        conv[1].weight = torch.nn.Parameter(prune_layer_weights[indx])

#        conv2= list(layer.named_modules())[4]
#        conv2[1].weight = torch.nn.Parameter(res_layer_weights[indx])
#        indx += 1
#torch.save({'model_state_dict': deblur_model.state_dict()}, 'pruned_model.pth')
#pruned_filters = 0
#tot_filter = 0
#for layer in model.modules():
#    if str(type(layer)) == '<class \'model.MSSNet.ResBlock\'>':
#        conv = list(layer.named_modules())[2]
#        param = conv[1].weight
#        print(param)
#            # print(torch.count_nonzero(param[:,0,0,0],dim=0)/param.shape[0])
#        pruned_filters += torch.count_nonzero(param[:, 0, 0, 0], dim=0)
#        tot_filter += param.shape[0]
#print(pruned_filters / tot_filter)

#torch.save({'model_state_dict':model.state_dict()},'model_eval.pth')


#psnr = [29.58468646501758, 29.59807830222471, 29.617120155524866, 29.515764226486645, 29.533600856631182, 29.71611982830483, 29.75158495156822, 29.69525233962409, 29.640195165629205, 29.71349905929964, 29.60711536849378,
#29.760019980083197, 29.921041357072998, 29.88997727886681, 29.92576536970888, 29.971932100625608, 30.129606160656124, 30.08975107170021, 29.84504670778799, 30.10701812299712, 30.26118248718098, 30.223370526271434,
#30.242596052979998, 30.197065188339643, 30.334396925988454, 30.35117088301492, 30.287821933457305, 30.321555250176385, 30.40139914851916, 30.452110393885143, 30.406512789261594, 30.510726233240664, 30.68131965691167,
#30.694982577339243, 30.746708368648207, 30.6995443437271, 30.74256602747929, 30.71518415954038, 30.74043544982681, 30.663172572741683, 30.799573397155676, 30.759869898768713, 30.826107660133385, 30.738235108557436,
#30.874286086508505, 30.761494637918187, 30.85096032239009, 30.96478984225327, 30.871027184775553, 30.950645688150203, 30.852615289700818, 30.837053420728086, 30.971685507518586, 30.998408196490715,
#31.104546020576304, 31.114257234634074, 31.133943944146584, 31.13315475575797, 31.07618230959034, 31.234932468226333, 31.087912155856728, 31.254935130793754, 31.261900891727436, 31.26430398948586,
#31.355645662156554, 31.413300885965402, 31.387703576201456, 31.379347455326766, 31.49444922951084, 31.505161479539268, 31.593475833067195, 31.62479816752709, 31.665906611199148, 31.701926255705327, 31.817425774421004,
#31.858573913552437, 31.961757866005218, 32.02719421532809, 32.22656719006966, 32.592781534761876, 33.01]
#spar = [0.12503135, 0.1256584, 0.12841736,0.13167796,0.13606723,0.14095812,0.14509657,0.14998746,0.15299724,0.15801355,0.16328067,0.1687986,0.17356409,0.17757712,0.18234262,0.18748432,0.19300225,0.1986456,0.20303486,
#0.20892902,0.2134437,0.2185854,0.22322549,0.22799097, 0.23413594, 0.2401555,0.24742915, 0.25445196, 0.26122397, 0.26874843, 0.27552044, 0.28367195, 0.28994232, 0.29671434, 0.3061199, 0.31188864, 0.32141963, 0.32869327,
#0.33521444,0.34324053, 0.34913468, 0.35628292, 0.36493605, 0.37183347, 0.37860548, 0.3858791, 0.394156, 0.40180588,0.4100828, 0.41848508,0.42789066, 0.43692, 0.44645098, 0.4567344,0.46777025, 0.47930774,0.49172312,0.5050163,
#0.51730627, 0.5313519, 0.54577374, 0.5609481, 0.5748683, 0.59129673, 0.6074743, 0.6246551, 0.6419614, 0.6610233, 0.6817156, 0.6998997, 0.72021574, 0.74078256, 0.76272887, 0.784926, 0.8082518, 0.8333333, 0.86029595, 0.8905192,
#0.9236268, 0.96124905, 1.0]
#ssim = [0.9293140128429251, 0.9297555763371671, 0.9300074121846904, 0.9291358019831372, 0.9288208020044596, 0.9313956072585847, 0.9325480220234147, 0.9317290967482903, 0.929736886981583, 0.9315281459922515, 0.9302318719032109,
#        0.9333668001914861, 0.9345725482911489, 0.9344830788759151, 0.9343315544802256, 0.935599556010012, 0.9375024330068772, 0.9367523369329883, 0.932436471528346, 0.9371539090905073, 0.9393096343554643,0.9386457742923664,
#        0.9390090577887802, 0.9383041871012491, 0.940045291298043, 0.9398115160870831, 0.9401177516614501, 0.9399803542103669, 0.9407719626392361, 0.9409093741465001, 0.940904533938177, 0.9412139544714474, 0.9439064360866667,
#        0.9442988464040438, 0.944947111831926, 0.9441942974965278, 0.944784578281303, 0.9447575885899747, 0.9443882771379555, 0.9439495726816296, 0.9454354676547939, 0.944556701194049, 0.9450661145707275, 0.9443697899338579,
#        0.9458702283866979, 0.9448778740894033, 0.9458212209756475, 0.946849427761847, 0.9461090785763909, 0.9470221525264366, 0.9458065480932687, 0.9450468237500916, 0.9466584789978288, 0.9475390400358624, 0.9491168814774144,
#        0.9486073758771675, 0.9486690284860338, 0.948556774860025, 0.9487038077694354, 0.9500384242764257, 0.9492230960423618, 0.9505293184202281, 0.9502469196070646, 0.9505920461659814, 0.9512271193852841, 0.9517933964514711,
#        0.9517677873775403, 0.9515042573776897, 0.9529039107605104, 0.9531601855714079, 0.953974276325061, 0.9541316371474794, 0.9547673365642744, 0.955052980316533, 0.9561011909258248, 0.9565145093830291, 0.9573517938007866,
#        0.9579975772934063, 0.959772814135633, 0.9625288515773365, 0.9656]

#psnr = np.array(psnr)
#print(np.argwhere(psnr == 30.510726233240664))
#print(psnr[31])
#print(ssim[31])
#print(spar[31])
#dir = sorted(os.listdir('./pruned_models'))[::-1]
#print(dir[31])
#plt.plot(spar, psnr, color="C0", label="PSNR")
#plt.legend()
#plt.title('Pruning PSNR Results')
#plt.ylabel('PSNR (db)')
#plt.xlabel('Prunable Filters Remaining (%)')
#plt.savefig('psnr_plot', bbox_inches='tight')
#plt.show()

#plt.plot(spar, ssim, color="C0", label="SSIM")
#plt.legend()
#plt.title('Pruning SSIM Results')
#plt.ylabel('SSIM')
#plt.xlabel('Prunable Filters Remaining (%)')
#plt.savefig('SSIM_plot', bbox_inches='tight')
#plt.show()
